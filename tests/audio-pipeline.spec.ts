import { test, expect } from '@playwright/test';

// Configure browser to allow microphone and use fake media
test.use({
  permissions: ['microphone'],
  launchOptions: {
    args: [
      '--use-fake-device-for-media-stream',
      '--use-fake-ui-for-media-stream',
      '--autoplay-policy=no-user-gesture-required',
    ],
  },
});

test.describe('Audio Pipeline Tests', () => {

  test('should establish audio pipeline end-to-end', async ({ page, context }) => {
    // Grant permissions at context level
    await context.grantPermissions(['microphone'], { origin: 'http://localhost:3000' });

    // Collect console logs
    const consoleLogs: { type: string; text: string }[] = [];
    page.on('console', msg => {
      consoleLogs.push({ type: msg.type(), text: msg.text() });
    });

    // Collect WebSocket connections
    const websockets: string[] = [];
    page.on('websocket', ws => {
      websockets.push(ws.url());
      console.log('WebSocket opened:', ws.url());
    });

    // Navigate to app
    await page.goto('http://localhost:3000');
    await page.waitForSelector('.lesson-layout', { timeout: 10000 });

    console.log('âœ… Page loaded successfully');

    // Click connect button
    const connectButton = page.locator('.call-button.connect').first();
    await expect(connectButton).toBeVisible();
    await connectButton.click({ force: true });

    console.log('âœ… Clicked connect button');

    // Wait for and accept permission modal
    const startButton = page.locator('button:has-text("Start! ðŸš€")');
    await startButton.waitFor({ timeout: 3000 });
    await startButton.click();

    console.log('âœ… Accepted permission modal');

    // Wait for connection to establish
    await page.waitForTimeout(8000);

    // Analyze console logs
    console.log('\n=== CONSOLE LOG ANALYSIS ===');

    // Check for token fetch
    const tokenFetchLogs = consoleLogs.filter(log => 
      log.text.includes('[CLIENT] Fetching') && log.text.includes('token')
    );
    console.log('Token fetch attempts:', tokenFetchLogs.length);
    expect(tokenFetchLogs.length).toBeGreaterThan(0);

    // Check for token received
    const tokenReceivedLogs = consoleLogs.filter(log => 
      log.text.includes('[CLIENT]') && log.text.includes('token received')
    );
    console.log('Token received:', tokenReceivedLogs.length > 0 ? 'âœ…' : 'âŒ');
    expect(tokenReceivedLogs.length).toBeGreaterThan(0);

    // Check for connection opened
    const connectionOpenedLogs = consoleLogs.filter(log => 
      log.text.includes('[LiveAPI] Connection opened successfully') ||
      log.text.includes('Connected successfully')
    );
    console.log('Connection opened:', connectionOpenedLogs.length > 0 ? 'âœ…' : 'âŒ');
    expect(connectionOpenedLogs.length).toBeGreaterThan(0);

    // Check for AudioRecorder initialization
    const audioRecorderLogs = consoleLogs.filter(log => 
      log.text.includes('[AudioRecorder] Got microphone stream')
    );
    console.log('Microphone stream obtained:', audioRecorderLogs.length > 0 ? 'âœ…' : 'âŒ');
    expect(audioRecorderLogs.length).toBeGreaterThan(0);

    // Check for AudioContext created
    const audioContextLogs = consoleLogs.filter(log => 
      log.text.includes('[AudioRecorder] Audio context created')
    );
    console.log('Audio context created:', audioContextLogs.length > 0 ? 'âœ…' : 'âŒ');
    expect(audioContextLogs.length).toBeGreaterThan(0);

    // Check audio context state
    const audioContextRunning = consoleLogs.some(log => 
      log.text.includes('Audio context created') && log.text.includes('running')
    );
    console.log('Audio context state: running:', audioContextRunning ? 'âœ…' : 'âŒ');
    
    // Check for Media stream source created
    const mediaStreamSourceLogs = consoleLogs.filter(log => 
      log.text.includes('[AudioRecorder] Media stream source created successfully')
    );
    console.log('Media stream source created:', mediaStreamSourceLogs.length > 0 ? 'âœ…' : 'âŒ');
    expect(mediaStreamSourceLogs.length).toBeGreaterThan(0);

    // Check for screen sharing
    const screenSharingLogs = consoleLogs.filter(log => 
      log.text.includes('[Vision] Starting JPEG frame capture') ||
      log.text.includes('[ScreenRecorder] Screen share granted')
    );
    console.log('Screen sharing active:', screenSharingLogs.length > 0 ? 'âœ…' : 'âš ï¸  (optional)');

    // Check for errors
    const errorLogs = consoleLogs.filter(log => log.type === 'error');
    console.log('\n=== ERROR ANALYSIS ===');
    
    const tokenErrors = errorLogs.filter(log => 
      log.text.includes('token') && log.text.toLowerCase().includes('used too many times')
    );
    console.log('Token exhaustion errors:', tokenErrors.length);
    expect(tokenErrors.length).toBe(0);

    const audioRecorderErrors = errorLogs.filter(log => 
      log.text.includes('createMediaStreamSource') || 
      log.text.includes('Failed to initialize audio input')
    );
    console.log('AudioRecorder errors:', audioRecorderErrors.length);
    expect(audioRecorderErrors.length).toBe(0);

    const connectionErrors = errorLogs.filter(log => 
      log.text.includes('Connection closed') || 
      log.text.includes('Connection error')
    );
    console.log('Connection errors:', connectionErrors.length);

    // Log critical errors
    if (errorLogs.length > 0) {
      console.log('\n=== ALL ERRORS ===');
      errorLogs.forEach(log => console.log('âŒ', log.text));
    }

    // Check WebSocket connection
    console.log('\n=== WEBSOCKET ANALYSIS ===');
    const geminiWebSocket = websockets.find(url => 
      url.includes('generativelanguage.googleapis.com')
    );
    console.log('Gemini WebSocket:', geminiWebSocket ? 'âœ…' : 'âŒ');
    console.log('WebSocket URL:', geminiWebSocket || 'Not found');

    // Visual check - buttons should be in connected state
    console.log('\n=== UI STATE ===');
    const disconnectButton = page.locator('.call-button.disconnect');
    const isConnected = await disconnectButton.isVisible();
    console.log('UI shows connected state:', isConnected ? 'âœ…' : 'âŒ');
    expect(isConnected).toBeTruthy();

    // Check for audio streamer initialization
    const audioStreamerLogs = consoleLogs.filter(log => 
      log.text.includes('[AudioStreamer]')
    );
    console.log('\n=== AUDIO OUTPUT PIPELINE ===');
    console.log('AudioStreamer logs found:', audioStreamerLogs.length);

    // Summary
    console.log('\n=== TEST SUMMARY ===');
    console.log('âœ… Token fetched and received');
    console.log('âœ… Connection established');
    console.log('âœ… Microphone stream obtained');
    console.log('âœ… Audio context created and running');
    console.log('âœ… Media stream source created');
    console.log('âœ… No token exhaustion errors');
    console.log('âœ… No AudioRecorder errors');
    console.log('âœ… UI shows connected state');
    
    if (geminiWebSocket) {
      console.log('âœ… Gemini WebSocket connected');
    } else {
      console.log('âš ï¸  Gemini WebSocket not detected');
    }

    // Wait a bit longer to see if any audio messages arrive
    console.log('\n=== WAITING FOR AUDIO DATA ===');
    console.log('Waiting 5 seconds for potential audio responses...');
    await page.waitForTimeout(5000);

    // Check for audio data received
    const audioDataLogs = consoleLogs.filter(log => 
      log.text.includes('[Audio] Received audio data from Gemini') ||
      log.text.includes('[AudioStreamer] Received PCM16 chunk') ||
      log.text.includes('[LiveClient] Audio parts:')
    );
    
    if (audioDataLogs.length > 0) {
      console.log('âœ… Audio data detected:', audioDataLogs.length, 'messages');
      audioDataLogs.forEach(log => console.log('  -', log.text));
    } else {
      console.log('â„¹ï¸  No audio data detected (expected if Gemini hasn\'t spoken yet)');
      console.log('   This is normal - Gemini only speaks when you talk to it first');
    }

    // Check for audio output transcription
    const transcriptionLogs = consoleLogs.filter(log => 
      log.text.includes('outputTranscription') || 
      log.text.includes('inputTranscription')
    );
    
    if (transcriptionLogs.length > 0) {
      console.log('âœ… Transcription detected:', transcriptionLogs.length, 'messages');
    } else {
      console.log('â„¹ï¸  No transcription detected (conversation hasn\'t started)');
    }

    console.log('\n=== AUDIO PIPELINE STATUS ===');
    console.log('ðŸŽ¤ INPUT PIPELINE:  âœ… Ready (microphone â†’ Gemini)');
    console.log('ðŸ”Š OUTPUT PIPELINE: âœ… Ready (Gemini â†’ speakers)');
    console.log('â³ WAITING FOR:    User to speak to trigger Gemini response');
    console.log('\nâ„¹ï¸  The pipeline is ready but needs user interaction to test full audio flow.');
  });

  test('should verify token server returns multi-use tokens', async ({ page }) => {
    // Test token endpoint directly
    const response = await page.request.post('http://localhost:3001/token');
    const responseBody = await response.json();
    
    console.log('\n=== TOKEN SERVER TEST ===');
    console.log('Status:', response.status());
    console.log('Response:', JSON.stringify(responseBody, null, 2));
    
    expect(response.status()).toBe(200);
    expect(responseBody.token).toBeDefined();
    
    // If using fallback (API key directly), log warning
    if (responseBody.fallback) {
      console.log('âš ï¸  Using API key fallback (not ephemeral token)');
      console.log('   Token can be used multiple times');
    } else if (responseBody.ephemeral) {
      console.log('âœ… Using ephemeral token');
      console.log('   Token supports multiple uses');
    }
  });

  test('should not show token exhaustion errors on reconnect', async ({ page, context }) => {
    await context.grantPermissions(['microphone'], { origin: 'http://localhost:3000' });

    const errorLogs: string[] = [];
    page.on('console', msg => {
      if (msg.type() === 'error') {
        errorLogs.push(msg.text());
      }
    });

    await page.goto('http://localhost:3000');
    await page.waitForSelector('.lesson-layout', { timeout: 10000 });

    // First connection
    console.log('\n=== FIRST CONNECTION ===');
    await page.locator('.call-button.connect').first().click({ force: true });
    await page.locator('button:has-text("Start! ðŸš€")').click();
    await page.waitForTimeout(5000);

    const firstConnectErrors = errorLogs.filter(e => 
      e.includes('token') && e.toLowerCase().includes('used too many times')
    );
    console.log('Token errors after first connect:', firstConnectErrors.length);
    expect(firstConnectErrors.length).toBe(0);

    // Disconnect
    console.log('\n=== DISCONNECTING ===');
    await page.locator('.call-button.disconnect').click();
    await page.waitForTimeout(2000);

    // Reconnect
    console.log('\n=== RECONNECTING ===');
    const initialErrorCount = errorLogs.length;
    await page.locator('.call-button.connect').first().click({ force: true });
    await page.waitForTimeout(5000);

    const newErrors = errorLogs.slice(initialErrorCount);
    const tokenExhaustionErrors = newErrors.filter(e => 
      e.includes('token') && e.toLowerCase().includes('used too many times')
    );
    
    console.log('New errors after reconnect:', newErrors.length);
    console.log('Token exhaustion errors:', tokenExhaustionErrors.length);
    
    expect(tokenExhaustionErrors.length).toBe(0);
    
    console.log('âœ… Reconnection works without token exhaustion');
  });
});
